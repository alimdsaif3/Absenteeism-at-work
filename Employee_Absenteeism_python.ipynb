{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from fancyimpute import KNN\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#import libraries for plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting working directory\n",
    "os.chdir(\"C:/Users/Mayank/Desktop/Edwisor/Projects/Project 2\")\n",
    "\n",
    "# Loading data\n",
    "emp_absent = pd.read_excel(\"Absenteeism_at_work.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_absent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 rows of data\n",
    "emp_absent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Types of all the variables\n",
    "emp_absent.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Unique values present in each variable\n",
    "emp_absent.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data types\n",
    "emp_absent['ID'] = emp_absent['ID'].astype('category')\n",
    "\n",
    "emp_absent['Reason for absence'] = emp_absent['Reason for absence'].replace(0,20)\n",
    "emp_absent['Reason for absence'] = emp_absent['Reason for absence'].astype('category')\n",
    "\n",
    "emp_absent['Month of absence'] = emp_absent['Month of absence'].replace(0,np.nan)\n",
    "emp_absent['Month of absence'] = emp_absent['Month of absence'].astype('category')\n",
    "\n",
    "emp_absent['Day of the week'] = emp_absent['Day of the week'].astype('category')\n",
    "emp_absent['Seasons'] = emp_absent['Seasons'].astype('category')\n",
    "emp_absent['Disciplinary failure'] = emp_absent['Disciplinary failure'].astype('category')\n",
    "emp_absent['Education'] = emp_absent['Education'].astype('category')\n",
    "emp_absent['Son'] = emp_absent['Son'].astype('category')\n",
    "emp_absent['Social drinker'] = emp_absent['Social drinker'].astype('category')\n",
    "emp_absent['Social smoker'] = emp_absent['Social smoker'].astype('category')\n",
    "emp_absent['Pet'] = emp_absent['Pet'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of dataframe\n",
    "df = emp_absent.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the EDA and problem statement file categorising the variables in two category \" Continuos\" and \"Categorical\"\n",
    "continuous_vars = ['Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Transportation expense',\n",
    "       'Hit target', 'Weight', 'Height', 'Body mass index', 'Absenteeism time in hours']\n",
    "\n",
    "categorical_vars = ['ID','Reason for absence','Month of absence','Day of the week',\n",
    "                     'Seasons','Disciplinary failure', 'Education', 'Social drinker',\n",
    "                     'Social smoker', 'Pet', 'Son']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe with number of missing values\n",
    "missing_val = pd.DataFrame(df.isnull().sum())\n",
    "\n",
    "#Reset the index to get row names as columns\n",
    "missing_val = missing_val.reset_index()\n",
    "\n",
    "#Rename the columns\n",
    "missing_val = missing_val.rename(columns = {'index': 'Variables', 0: 'Missing_perc'})\n",
    "missing_val\n",
    "\n",
    "#Calculate percentage\n",
    "missing_val['Missing_perc'] = (missing_val['Missing_perc']/len(df))*100\n",
    "\n",
    "#Sort the rows according to decreasing missing percentage\n",
    "missing_val = missing_val.sort_values('Missing_perc', ascending = False).reset_index(drop = True)\n",
    "\n",
    "#Save output to csv file\n",
    "missing_val.to_csv(\"Missing_perc.csv\", index = False)\n",
    "\n",
    "missing_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual value = 31\n",
    "#Mean = 26.67\n",
    "#Median = 25\n",
    "#KNN = 30.80\n",
    "print(df['Body mass index'].iloc[1])\n",
    "\n",
    "#Set the value of first row in Body mass index as NAN\n",
    "#create missing value\n",
    "df['Body mass index'].iloc[1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute with mean\n",
    "#df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].mean())\n",
    "\n",
    "#Impute with median\n",
    "#df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].median())\n",
    "\n",
    "#Apply KNN imputation algorithm\n",
    "df = pd.DataFrame(KNN(k = 3).fit_transform(df), columns = df.columns)\n",
    "df['Body mass index'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round the values of categorical values\n",
    "for i in categorical_vars:\n",
    "    df.loc[:,i] = df.loc[:,i].round()    \n",
    "    df.loc[:,i] = df.loc[:,i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if any missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of data using graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the bar graph of categorical Data using factorplot\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.factorplot(data=df, x='Reason for absence', kind= 'count',size=4,aspect=2)\n",
    "sns.factorplot(data=df, x='Seasons', kind= 'count',size=4,aspect=2)\n",
    "sns.factorplot(data=df, x='Education', kind= 'count',size=4,aspect=2)\n",
    "sns.factorplot(data=df, x='Disciplinary failure', kind= 'count',size=4,aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the distribution of numerical data using histogram\n",
    "plt.hist(data=df, x='Weight', bins='auto', label='Weight')\n",
    "plt.xlabel('Weight')\n",
    "plt.title(\"Weight Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the distribution of numerical data using histogram\n",
    "plt.hist(data=df, x='Age', bins='auto', label='Age')\n",
    "plt.xlabel('Age')\n",
    "plt.title(\"Age Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the distribution of Temperature and Humdity against Bike rental count using scatter plot\n",
    "fig, axs = plt.subplots(1,2, figsize=(15, 5), sharey=True)\n",
    "axs[0].scatter(data=df, x='Age', y='Absenteeism time in hours')\n",
    "axs[1].scatter(data=df, x='Weight', y='Absenteeism time in hours', color = 'red')\n",
    "fig.suptitle('Scatter plot for Age and Weight')\n",
    "plt.xlabel(\"Humidity\")\n",
    "plt.ylabel(\"Count of bikes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for outliers in data using boxplot\n",
    "sns.boxplot(data=df[['Absenteeism time in hours','Body mass index','Height','Weight']])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for outliers in data using boxplot\n",
    "sns.boxplot(data=df[['Hit target','Service time','Age','Transportation expense']])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for outliers using boxplots\n",
    "for i in continuous_vars:\n",
    "    # Getting 75 and 25 percentile of variable \"i\"\n",
    "    q75, q25 = np.percentile(df[i], [75,25])\n",
    "    \n",
    "    # Calculating Interquartile range\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    # Calculating upper extream and lower extream\n",
    "    minimum = q25 - (iqr*1.5)\n",
    "    maximum = q75 + (iqr*1.5)\n",
    "    \n",
    "    # Replacing all the outliers value to NA\n",
    "    df.loc[df[i]< minimum,i] = np.nan\n",
    "    df.loc[df[i]> maximum,i] = np.nan\n",
    "\n",
    "\n",
    "# Impute missing values with KNN\n",
    "df = pd.DataFrame(KNN(k = 3).fit_transform(df), columns = df.columns)\n",
    "# Checking if there is any missing value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for outliers in data using boxplot\n",
    "sns.boxplot(data=df[['Absenteeism time in hours','Body mass index','Height','Weight']])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for outliers in data using boxplot\n",
    "sns.boxplot(data=df[['Hit target','Service time','Age','Transportation expense']])\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dataframe with all continuous variables\n",
    "df_corr = df.loc[:,continuous_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for multicollinearity using corelation graph\n",
    "#Set the width and hieght of the plot\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "#Generate correlation matrix\n",
    "corr = df_corr.corr()\n",
    "\n",
    "#Plot using seaborn library\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), \n",
    "            cmap=sns.diverging_palette(220, 50, as_cmap=True),\n",
    "            square=True, ax=ax, annot = True)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Reduction\n",
    "to_drop = ['Weight']\n",
    "df = df.drop(to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the Continuous and Categorical Variables\n",
    "continuous_vars.remove('Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of clean data and export it as excel file\n",
    "clean_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality check\n",
    "for i in continuous_vars:\n",
    "    if i == 'Absenteeism time in hours':\n",
    "        continue\n",
    "    sns.distplot(df[i],bins = 'auto')\n",
    "    plt.title(\"Checking Distribution for Variable \"+str(i))\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of continuous variables\n",
    "for i in continuous_vars:\n",
    "    if i == 'Absenteeism time in hours':\n",
    "        continue\n",
    "    df[i] = (df[i] - df[i].min())/(df[i].max()-df[i].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables of factor variables\n",
    "df = pd.get_dummies(data = df, columns = categorical_vars)\n",
    "\n",
    "# Copying dataframe\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observe the first row\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( df.iloc[:, df.columns != 'Absenteeism time in hours'], df.iloc[:, 8], test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "#RMSE: 4.056\n",
    "#R-squared: -0.4481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for Decision Tree \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Build decsion tree using DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(random_state = 1).fit(X_train,y_train)\n",
    "\n",
    "#Perdict for test cases\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "#Create data frame for actual and predicted values\n",
    "df_dt = pd.DataFrame({'actual': y_test, 'pred': dt_predictions})\n",
    "print(df_dt.head())\n",
    "\n",
    "#Define function to calculate RMSE\n",
    "def RMSE(y_actual,y_predicted):\n",
    "    rmse = np.sqrt(mean_squared_error(y_actual,y_predicted))\n",
    "    return rmse\n",
    "\n",
    "#Calculate RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, dt_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, dt_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "#RMSE: 2.7114\n",
    "#R-squared: 0.353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Build random forest using RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators = 500, random_state = 1).fit(X_train,y_train)\n",
    "\n",
    "#Perdict for test cases\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "#Create data frame for actual and predicted values\n",
    "df_rf = pd.DataFrame({'actual': y_test, 'pred': rf_predictions})\n",
    "print(df_rf.head())\n",
    "\n",
    "#Calculate RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, rf_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, rf_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "#RMSE: 40145e+8\n",
    "#R-squared: -1.4181e+24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Train the model\n",
    "lr_model = LinearRegression().fit(X_train , y_train)\n",
    "\n",
    "#Perdict for test cases\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "#Create data frame for actual and predicted values\n",
    "df_lr = pd.DataFrame({'actual': y_test, 'pred': lr_predictions})\n",
    "print(df_lr.head())\n",
    "\n",
    "#Calculate RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, lr_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, lr_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the target variable\n",
    "target = df['Absenteeism time in hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of rows and columns of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library for PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Converting data to numpy array\n",
    "X = df.values\n",
    "\n",
    "#Data has 116 variables so no of components of PCA = 115\n",
    "pca = PCA(n_components=115)\n",
    "pca.fit(X)\n",
    "\n",
    "#Proportion of variance explained\n",
    "var= pca.explained_variance_ratio_\n",
    "\n",
    "#Cumulative scree plot\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "#Draw the plot\n",
    "plt.plot(var1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 45 components since it explains almost 95+ % data variance\n",
    "pca = PCA(n_components=45)\n",
    "\n",
    "#Fitting the selected components to the data\n",
    "pca.fit(X)\n",
    "\n",
    "#Splitting data into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,target, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "#RMSE: 0.0353\n",
    "#R-squared: 0.9998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build decsion tree using DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(random_state = 1).fit(X_train,y_train)\n",
    "\n",
    "#Perdict for test cases\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "#Create data frame for actual and predicted values\n",
    "df_dt = pd.DataFrame({'actual': y_test, 'pred': dt_predictions})\n",
    "print(df_dt.head())\n",
    "\n",
    "#Calculate RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, dt_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, dt_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "#RMSE: 0.04453\n",
    "#R-squared: 0.9998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build random forest using RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators = 500, random_state = 1).fit(X_train,y_train)\n",
    "\n",
    "#Perdict for test cases\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "#Create data frame for actual and predicted values\n",
    "df_rf = pd.DataFrame({'actual': y_test, 'pred': rf_predictions})\n",
    "print(df_rf.head())\n",
    "\n",
    "#Calculate RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, rf_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, rf_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "#RMSE: 0.0013\n",
    "#R-squared: 0.9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Train the model\n",
    "lr_model = LinearRegression().fit(X_train , y_train)\n",
    "\n",
    "#Perdict for test cases\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "#Create data frame for actual and predicted values\n",
    "df_lr = pd.DataFrame({'actual': y_test, 'pred': lr_predictions})\n",
    "print(df_lr.head())\n",
    "\n",
    "#Calculate RMSE and R-squared value\n",
    "print(\"Root Mean Squared Error: \"+str(RMSE(y_test, lr_predictions)))\n",
    "print(\"R^2 Score(coefficient of determination) = \"+str(r2_score(y_test, lr_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
